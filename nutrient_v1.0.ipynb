{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's study LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "from langchain.schema import Document\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "from langchain.document_loaders import PyMuPDFLoader,ArxivLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.document_transformers import LongContextReorder\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda\n",
    "from langchain.schema.runnable.passthrough import RunnableAssign\n",
    "from operator import itemgetter\n",
    "\n",
    "from faiss import IndexFlatL2\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "from functools import partial\n",
    "from rich.console import Console\n",
    "from rich.style import Style\n",
    "from rich.theme import Theme\n",
    "\n",
    "console = Console()\n",
    "base_style = Style(color=\"#76B900\", bold=True)\n",
    "pprint = partial(console.print, style=base_style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the nvidia study exercise, they use \n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "llm = OllamaLLM(model=\"llama3.1:8b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create vector stores from nutrient papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available Documents:\n",
      " - Within-person comparison of eating behaviors, time of eating, and dietary intake on days with and without breakfast: NHANES 2005–20101–3\n",
      " - Nutrient Intakes from Meals and Snacks Differ with Age in Middle-Aged and Older Americans\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "docs = []\n",
    "for fname in os.listdir(\"./PAPER_DOCS/\"):\n",
    "    loader = PyMuPDFLoader(f\"./PAPER_DOCS/{fname}\")\n",
    "    docs.append(loader.load())\n",
    "\n",
    "for doc in docs:\n",
    "    content = json.dumps(doc[0].page_content)\n",
    "    if \"References\" in content:\n",
    "        doc[0].page_content = content[:content.index(\"References\")]\n",
    "\n",
    "# print(\"Chunking Documents\")\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=100,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \";\", \",\", \" \"],\n",
    ")\n",
    "docs_chunks = [text_splitter.split_documents(doc) for doc in docs]\n",
    "docs_chunks = [[c for c in dchunks if len(c.page_content) > 200] for dchunks in docs_chunks]\n",
    "\n",
    "# ## Make some custom Chunks to give big-picture details\n",
    "doc_string = \"Available Documents:\"\n",
    "doc_metadata = []\n",
    "for chunks in docs_chunks:\n",
    "    metadata = getattr(chunks[0], 'metadata', {})\n",
    "    doc_string += \"\\n - \" + metadata['title']\n",
    "    doc_metadata += [str(metadata)]\n",
    "\n",
    "extra_chunks = [doc_string] + doc_metadata\n",
    "print(doc_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing Vector Stores\n",
      "CPU times: total: 484 ms\n",
      "Wall time: 907 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(\"Constructing Vector Stores\")\n",
    "vecstores = [FAISS.from_texts(extra_chunks, embeddings)]\n",
    "vecstores += [FAISS.from_documents(doc_chunks, embeddings) for doc_chunks in docs_chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructed aggregate docstore with 115 chunks\n"
     ]
    }
   ],
   "source": [
    "embed_dims = len(embeddings.embed_query(\"test\"))\n",
    "def default_FAISS():\n",
    "    '''Useful utility for making an empty FAISS vectorstore'''\n",
    "    return FAISS(\n",
    "        embedding_function=embeddings,\n",
    "        index=IndexFlatL2(embed_dims),\n",
    "        docstore=InMemoryDocstore(),\n",
    "        index_to_docstore_id={},\n",
    "        normalize_L2=False\n",
    "    )\n",
    "\n",
    "def aggregate_vstores(vectorstores):\n",
    "    ## Initialize an empty FAISS Index and merge others into it\n",
    "    ## We'll use default_faiss for simplicity, though it's tied to your embedder by reference\n",
    "    agg_vstore = default_FAISS()\n",
    "    for vstore in vectorstores:\n",
    "        agg_vstore.merge_from(vstore)\n",
    "    return agg_vstore\n",
    "\n",
    "## Unintuitive optimization; merge_from seems to optimize constituent vector stores away\n",
    "docstore = aggregate_vstores(vecstores)\n",
    "\n",
    "print(f\"Constructed aggregate docstore with {len(docstore.docstore._dict)} chunks\")\n",
    "docstore.save_local(\"docstore_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example tabular data\n",
    "table_data = [\n",
    "    {\"Product Name\": \"Widget A\", \"Price\": \"$10\", \"Category\": \"Electronics\", \"Availability\": \"In Stock\"},\n",
    "    {\"Product Name\": \"Widget B\", \"Price\": \"$15\", \"Category\": \"Electronics\", \"Availability\": \"Out of Stock\"},\n",
    "    {\"Product Name\": \"Gadget X\", \"Price\": \"$25\", \"Category\": \"Home Goods\", \"Availability\": \"In Stock\"},\n",
    "]\n",
    "\n",
    "# Concatenate fields into a single string representation for each row\n",
    "row_texts = [\n",
    "    f\"{row['Product Name']} {row['Category']} {row['Price']} {row['Availability']}\"\n",
    "    for row in table_data\n",
    "]\n",
    "\n",
    "menus = FAISS.from_texts(row_texts, embedding=embeddings)\n",
    "menu_retriever = menus.as_retriever()\n",
    "\n",
    "\n",
    "def docs2str(docs, title=\"Document\"):\n",
    "    \"\"\"Useful utility for making chunks into context string. Optional, but useful\"\"\"\n",
    "    out_str = \"\"\n",
    "    for doc in docs:\n",
    "        doc_name = getattr(doc, 'metadata', {}).get('Title', title)\n",
    "        if doc_name:\n",
    "            out_str += f\"[Quote from {doc_name}] \"\n",
    "        out_str += getattr(doc, 'page_content', str(doc)) + \"\\n\"\n",
    "    return out_str\n",
    "\n",
    "## Optional; Reorders longer documents to center of output text\n",
    "long_reorder = RunnableLambda(LongContextReorder().transform_documents)\n",
    "\n",
    "context_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Answer the question using only the context\"\n",
    "    \"\\n\\nRetrieved Context: {context}\"\n",
    "    \"\\n\\nUser Question: {question}\"\n",
    "    \"\\nAnswer the user conversationally. User is not aware of context.\"\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        'context': menu_retriever | long_reorder | docs2str,\n",
    "        'question': (lambda x:x)\n",
    "    }\n",
    "    | context_prompt\n",
    "    # | RPrint()\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"So you're looking for a list, huh? Let me see what I have here...\\n\\nAlright, I've got a few things listed out. There's a Gadget X that costs $25 and it's in stock. Then there's two different Widgets - Widget B is actually out of stock, but Widget A is still available for $10.\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Give me the list of items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nutrient's related RAG\n",
    "\n",
    "I want the model to?\n",
    "1. Answer based on the current meal set provided\n",
    "2. Able to recommend menu depending on budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RPrint(preface=\"\"):\n",
    "    \"\"\"Simple passthrough \"prints, then returns\" chain\"\"\"\n",
    "    def print_and_return(x, preface):\n",
    "        if preface: print(preface, end=\"\")\n",
    "        pprint(x)\n",
    "        return x\n",
    "    return RunnableLambda(partial(print_and_return, preface=preface))\n",
    "\n",
    "def docs2str(docs, title=\"Document\"):\n",
    "    \"\"\"Useful utility for making chunks into context string. Optional, but useful\"\"\"\n",
    "    out_str = \"\"\n",
    "    for doc in docs:\n",
    "        doc_name = getattr(doc, 'metadata', {}).get('Title', title)\n",
    "        if doc_name:\n",
    "            out_str += f\"[Quote from {doc_name}] \"\n",
    "        out_str += getattr(doc, 'page_content', str(doc)) + \"\\n\"\n",
    "    return out_str\n",
    "long_reorder = RunnableLambda(LongContextReorder().transform_documents)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([(\"system\",\n",
    "    \"You are a document chatbot. Help the user as they ask questions about documents.\"\n",
    "    \" User messaged just asked: {input}\\n\\n\"\n",
    "    \" From this, we have retrieved the following potentially-useful info: \"\n",
    "    \" Document Retrieval:\\n{context}\\n\\n\"\n",
    "    \" (Answer only from retrieval. Only cite sources that are used. Make your response conversational.)\"\n",
    "), ('user', '{input}')])\n",
    "\n",
    "retrieval_chain = (\n",
    "    {'input' : (lambda x: x)}\n",
    "    | RunnableAssign({'context' : itemgetter('input') | docstore.as_retriever()  | long_reorder | docs2str})\n",
    ")\n",
    "\n",
    "stream_chain = chat_prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'How to balance my daily intake?',\n",
       " 'context': '[Quote from Document] for aging individuals are focused on meeting nutrients of concern, and modifying dietary intake\\npatterns to address their changing health and nutritional status, such as alterations in metabolism,\\ndigestion and absorption, and lifestyles. Suﬃcient nutrient intakes are also critically important for\\nmiddle-aged and older adults as aging is associated with increased risk of chronic diseases, such as\\ncardiovascular disease and diabetes, and sarcopenia, a gradual and progressive decline in muscle\\nmass, strength, and endurance [1,2]. Mounting evidence shows that the increasing prevalence of these\\nconditions at younger ages is not a normal function of aging, but rather a consequence of unhealthy\\nbehaviors [3–5]. Therefore, meeting the nutrient needs through healthy dietary patterns is key to\\nmaintaining good health for healthy aging.\\nNutrients 2019, 11, 1301; doi:10.3390/nu11061301\\nwww.mdpi.com/journal/nutrients\\n[Quote from Document] Nutrients 2019, 11, 1301\\n9 of 12\\nsupport nutrition education eﬀorts and more intervention targets to promote healthful aging. Eating\\noccasions aﬀord new opportunities to meet the day’s needs and numerous factors inﬂuence the intakes\\nin older adults [19,20]. Data from NHANES III (1988–1994) estimated less than two-thirds of adults\\nover 65 years ate three meals on the day of record, with greater frequency of eating related to higher\\nintakes of carbohydrates, ﬁber, and some micronutrients, as well as lower intakes of protein, fat, and\\nsodium [21]. Middle-aged adults with three or fewer eating occasions per day had signiﬁcantly higher\\npercent of energy from protein and lower percent of energy from carbohydrates than those with more\\neating occasions [22]. There is support for the frequency of consumption, but more is needed on the\\npotential health impact of missed meals, especially in aging. Including the foods typically consumed\\n[Quote from Document] intakes were signiﬁcantly higher for the 45–59 year group compared to the 60–70 and 71+ age groups\\n(p ≤0.001). Fiber showed mixed results, but breakfast intakes were signiﬁcantly higher in the oldest\\nadults for both mean and percent intakes (p < 0.001).\\n[Quote from Document] during eating occasions will help provide valuable formative data to inform strategies to optimize\\ndietary intakes in older adults.\\nThere is a paucity of data exploring the meal patterns of middle-aged and older adults,\\nand challenges persist with the classiﬁcation of intakes from a methodological standpoint [14].\\nLeech et al. [14] observed lunch and evening meals to contribute to the greatest proportion of total\\ndaily energy, protein, fat, and carbohydrate intake of adults from the UK, and main meals were where\\nthe largest volume of food was normally consumed. As well, those with a greater proportion of intakes\\nlater in the day were related to poorer diet quality and greater body mass index (BMI) [23]. Data from\\nthe present study indicate that dinner was the least skipped meal on the day of intake and was the\\nmain contributor to energy and most macronutrients for all ages in the U.S. population. In contrast,\\n'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval = retrieval_chain.invoke(\"How to balance my daily intake?\")\n",
    "# stream_chain.invoke(retrieval)\n",
    "retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for |: 'operator.itemgetter' and 'function'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 21\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(row) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows])\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# RunnableAssign for Tabular Data Retrieval\u001b[39;00m\n\u001b[0;32m     18\u001b[0m tabular_retrieval_chain \u001b[38;5;241m=\u001b[39m RunnableAssign({\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m: (\u001b[38;5;28;01mlambda\u001b[39;00m x: x),  \u001b[38;5;66;03m# Pass the input as-is\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m'\u001b[39m: (\n\u001b[1;32m---> 21\u001b[0m         itemgetter(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m)             \u001b[38;5;66;03m# Extract the input query\u001b[39;00m\n\u001b[0;32m     22\u001b[0m         \u001b[38;5;241m|\u001b[39m (\u001b[38;5;28;01mlambda\u001b[39;00m query: table_retriever(query, table_data))  \u001b[38;5;66;03m# Retrieve relevant rows\u001b[39;00m\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;241m|\u001b[39m rows_to_str                   \u001b[38;5;66;03m# Convert rows into a single string\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     )\n\u001b[0;32m     25\u001b[0m })\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'operator.itemgetter' and 'function'"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "table_data = [\n",
    "    {\"Product Name\": \"Widget A\", \"Price\": \"$10\", \"Category\": \"Electronics\", \"Availability\": \"In Stock\"},\n",
    "    {\"Product Name\": \"Widget B\", \"Price\": \"$15\", \"Category\": \"Electronics\", \"Availability\": \"Out of Stock\"},\n",
    "    {\"Product Name\": \"Gadget X\", \"Price\": \"$25\", \"Category\": \"Home Goods\", \"Availability\": \"In Stock\"},\n",
    "]\n",
    "# Custom Retriever for Tabular Data\n",
    "def table_retriever(query: str, table: List[dict]):\n",
    "    # Naive search: Match any value in the row with the query\n",
    "    results = [row for row in table if any(query.lower() in str(value).lower() for value in row.values())]\n",
    "    return results\n",
    "\n",
    "# Convert rows into a string format for context\n",
    "def rows_to_str(rows: List[dict]) -> str:\n",
    "    return \"\\n\".join([str(row) for row in rows])\n",
    "\n",
    "# RunnableAssign for Tabular Data Retrieval\n",
    "tabular_retrieval_chain = RunnableAssign({\n",
    "    'input': (lambda x: x),  # Pass the input as-is\n",
    "    'context': (\n",
    "        itemgetter('input')             # Extract the input query\n",
    "        | (lambda query: table_retriever(query, table_data))  # Retrieve relevant rows\n",
    "        | rows_to_str                   # Convert rows into a single string\n",
    "    )\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
